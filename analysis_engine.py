# -*- coding: utf-8 -*-
"""Google Hackathonipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-8iqTScxmS3OzIenY8zPG7SJvbmjvwfL
"""

# 3rd attempt

# The following command is for installing packages in the Google Colab environment.
# !pip install --upgrade google-cloud-aiplatform google-cloud-bigquery

import os
import json
from urllib.parse import urlparse

# --- Configuration ---
# Make sure you have authenticated with Google Cloud CLI and set your project:
# gcloud auth application-default login
#
# IMPORTANT: Replace 'YOUR_PROJECT_ID' with your actual Google Cloud Project ID.
# You can find your Project ID in the Google Cloud Console dashboard.
# gcloud config set project YOUR_PROJECT_ID

PROJECT_ID = "echo-mind-472808"

LOCATION = "asia-south1"  # Mumbai, India - Better for Indian context and reduced latency

from google.cloud import aiplatform
import vertexai
from vertexai.generative_models import GenerativeModel
from google.cloud import bigquery
import requests
from datetime import datetime

aiplatform.init(project=PROJECT_ID, location=LOCATION)
vertexai.init(project=PROJECT_ID, location=LOCATION)

print(f"✅ Vertex AI initialized for project: {PROJECT_ID}")

GEMINI_MODEL = "gemini-2.5-pro" # Using Gemini 2.5 Pro for enhanced fact-checking capabilities
TRUSTED_DOMAINS = [
    # Major Indian Sources
    "thehindu.com", "indiatoday.in", "timesofindia.indiatimes.com", "indianexpress.com", 
    "ndtv.com", "hindustantimes.com", "news18.com", "republicworld.com", "zeenews.india.com",
    # International Sources
    "bbc.com", "reuters.com", "nytimes.com", "cnn.com", "apnews.com"
]

def load_current_context():
    """
    Load current context from auto-updater system
    """
    try:
        import json
        if os.path.exists('current_context.json'):
            with open('current_context.json', 'r') as f:
                return json.load(f)
    except Exception as e:
        print(f"Warning: Could not load current context: {e}")
    return {}

def get_current_date_info():
    """
    Get current date and time information for AI context
    """
    from datetime import datetime
    now = datetime.now()
    return {
        'current_date': now.strftime('%Y-%m-%d'),
        'current_time': now.strftime('%H:%M:%S'),
        'day_of_week': now.strftime('%A'),
        'month': now.strftime('%B'),
        'year': now.year
    }

def search_current_info(query, max_results=3):
    """
    Search for current information using auto-updater context and fallback methods.
    This provides recent context for political and time-sensitive claims.
    """
    try:
        # Load current context from auto-updater
        current_context = load_current_context()
        current_info = []
        
        # Add current date information
        date_info = get_current_date_info()
        current_info.append(f"Current Date: {date_info['current_date']} ({date_info['day_of_week']})")
        
        # For ALL topics, provide context from auto-updater or fallback
        # Comprehensive topic detection
        topic_keywords = {
            'politics': ['cm', 'chief minister', 'prime minister', 'president', 'election', 'government', 'minister', 'parliament', 'assembly'],
            'health': ['covid', 'vaccine', 'health', 'medical', 'disease', 'treatment', 'hospital', 'doctor', 'medicine', 'healthcare'],
            'science': ['research', 'study', 'scientist', 'discovery', 'experiment', 'technology', 'innovation', 'space', 'climate change'],
            'technology': ['tech', 'software', 'app', 'internet', 'cyber', 'data', 'ai', 'artificial intelligence', 'smartphone', 'computer'],
            'business': ['stock', 'market', 'economy', 'finance', 'investment', 'banking', 'company', 'startup', 'industry'],
            'sports': ['cricket', 'football', 'hockey', 'tennis', 'olympics', 'ipl', 'fifa', 'world cup', 'player', 'match'],
            'entertainment': ['movie', 'film', 'bollywood', 'actor', 'actress', 'music', 'netflix', 'celebrity', 'award'],
            'education': ['school', 'college', 'university', 'student', 'exam', 'jee', 'neet', 'upsc', 'degree']
        }
        
        # Detect query topic
        query_topic = 'general'
        for topic, keywords in topic_keywords.items():
            if any(keyword in query.lower() for keyword in keywords):
                query_topic = topic
                break
        
        # Get comprehensive updates from auto-updater
        comprehensive_updates = current_context.get('comprehensive_updates', {})
        categorized_updates = current_context.get('categorized_updates', {})
        
        if query_topic != 'general' or any(any(keyword in query.lower() for keyword in keywords) for keywords in topic_keywords.values()):
            # Handle topic-specific information
            query_lower = query.lower()
            
            # Add topic-specific context
            current_info.append(f"Query Topic Detected: {query_topic.title()}")
            
            # Get relevant updates for the detected topic
            topic_updates = categorized_updates.get(query_topic, {})
            if topic_updates:
                current_info.append(f"Recent {query_topic.title()} Updates Available: {len(topic_updates)} items")
                # Add most recent updates (limit to 3 most recent)
                sorted_updates = sorted(topic_updates.items(), 
                                      key=lambda x: x[1].get('date', ''), reverse=True)
                for key, update in sorted_updates[:3]:
                    current_info.append(f"• {update['title']} - {update['source']} ({update['date'][:10]})")
            
            # Special handling for specific topics
            if query_topic == 'politics':
                # Political-specific logic (keep existing detailed political handling)
                political_updates = {k: v for k, v in comprehensive_updates.items() 
                                   if v.get('category') == 'politics' or v.get('type', '').endswith('_update')}
                
                # Look for state-specific updates
            indian_states = {
                'andhra pradesh': ('Chandrababu Naidu', 'TDP', 'June 2024'),
                'telangana': ('A. Revanth Reddy', 'Congress', 'December 2023'),
                'karnataka': ('Siddaramaiah', 'Congress', '2023'),
                'tamil nadu': ('M.K. Stalin', 'DMK', '2021'),
                'kerala': ('Pinarayi Vijayan', 'CPI(M)', '2021'),
                'maharashtra': ('Eknath Shinde', 'Shiv Sena', '2022'),
                'west bengal': ('Mamata Banerjee', 'AITC', '2011'),
                'uttar pradesh': ('Yogi Adityanath', 'BJP', '2017'),
                'gujarat': ('Bhupendra Patel', 'BJP', '2021'),
                'rajasthan': ('Ashok Gehlot', 'Congress', '2018')
            }
            
            # Look for state-specific updates
            for state, (cm_name, party, since) in indian_states.items():
                if state in query_lower and ('cm' in query_lower or 'chief minister' in query_lower):
                    state_key = state.replace(' ', '_') + '_cm'
                    if state_key in political_updates:
                        update = political_updates[state_key]
                        current_info.append(f"Latest News: {update['title']} - {update['source']} ({update['date'][:10]})")
                        if update.get('state'):
                            current_info.append(f"State: {update['state']}")
                    else:
                        # Fallback to known information
                        current_info.append(f"Current CM of {state.title()}: {cm_name} ({party}) since {since}")
                        current_info.append(f"Note: Please verify current status as political information changes frequently")
                    break
            
            # Check for PM updates
            if 'prime minister' in query_lower or ' pm ' in query_lower:
                if 'prime_minister' in political_updates:
                    update = political_updates['prime_minister']
                    current_info.append(f"Latest News: {update['title']} - {update['source']} ({update['date'][:10]})")
                else:
                    current_info.append("Current PM: Narendra Modi (BJP) since 2014 - verify for any recent changes")
            
            # Check for election updates
            if any(term in query_lower for term in ['election', 'vote', 'poll', 'ballot']):
                election_updates = {k: v for k, v in political_updates.items() if 'election' in k}
                if election_updates:
                    for election_type, update in election_updates.items():
                        current_info.append(f"Election Update: {update['title']} - {update['source']} ({update['date'][:10]})")
            
            # Check for party updates
            major_parties = ['bjp', 'congress', 'aap', 'brs', 'tdp', 'ysrcp', 'dmk', 'aiadmk']
            for party in major_parties:
                if party in query_lower:
                    party_key = f'{party}_update'
                    if party_key in political_updates:
                        update = political_updates[party_key]
                        current_info.append(f"{party.upper()} Update: {update['title']} - {update['source']} ({update['date'][:10]})")
                    break
            
            elif query_topic == 'health':
                # Health-specific guidance
                current_info.append("Health Information: Verify with official health authorities (WHO, CDC, ICMR, Ministry of Health)")
                if 'covid' in query_lower or 'vaccine' in query_lower:
                    current_info.append("COVID/Vaccine Info: Check latest guidelines from health.gov.in and WHO")
            
            elif query_topic == 'science':
                # Science-specific guidance
                current_info.append("Scientific Claims: Verify through peer-reviewed research and official scientific institutions")
                if 'climate' in query_lower:
                    current_info.append("Climate Information: Refer to IPCC reports and national meteorological departments")
            
            elif query_topic == 'technology':
                # Technology-specific guidance
                current_info.append("Technology News: Cross-check with official company announcements and tech publications")
                if any(term in query_lower for term in ['ai', 'artificial intelligence', 'data']):
                    current_info.append("AI/Data Claims: Verify with research institutions and official tech companies")
            
            elif query_topic == 'business':
                # Business-specific guidance
                current_info.append("Business/Finance Info: Verify with official financial institutions and regulatory bodies")
                if any(term in query_lower for term in ['stock', 'market', 'investment']):
                    current_info.append("Market Information: Cross-check with NSE, BSE, and financial regulatory authorities")
            
            elif query_topic == 'sports':
                # Sports-specific guidance
                current_info.append("Sports Information: Verify with official sports bodies and federations")
                if 'cricket' in query_lower:
                    current_info.append("Cricket Info: Check with BCCI, ICC, and official team websites")
            
            elif query_topic == 'entertainment':
                # Entertainment-specific guidance
                current_info.append("Entertainment News: Verify with official announcements and reputable film industry sources")
                if 'bollywood' in query_lower or 'movie' in query_lower:
                    current_info.append("Film Industry: Cross-check with official production houses and film bodies")
            
            elif query_topic == 'education':
                # Education-specific guidance
                current_info.append("Education Information: Verify with official educational institutions and government bodies")
                if any(term in query_lower for term in ['exam', 'result', 'admission']):
                    current_info.append("Academic Info: Check official exam board websites and institution announcements")
        
        # Add information about data freshness
        if current_context.get('last_updated'):
            last_updated = current_context['last_updated'][:10]  # Just date part
            current_info.append(f"Data last updated: {last_updated} from {len(current_context.get('trusted_sources', []))} trusted sources")
        
        # For non-political or when no specific updates found
        if len(current_info) <= 1:  # Only date info
            current_info.extend([
                f"For current information about '{query}', verify with recent news sources",
                "Check official government websites and trusted news outlets for latest updates",
                "Political information changes frequently - always verify current office holders"
            ])
        
        return current_info
    
    except Exception as e:
        print(f"Current info search error: {e}")
        return ["Unable to fetch current information - verify with recent reliable sources"]

def misinformation_detector_and_explainer(text):
    if not text or text.strip() == "":
        return {"classification": "NoText", "explanation": "No explanation (empty input).", "score": 0, "tips": []}

    # Get current context for enhanced AI analysis
    current_context = load_current_context()
    date_info = get_current_date_info()
    
    # Build dynamic context string
    context_info = f"Today's Date: {date_info['current_date']} ({date_info['day_of_week']})"
    if current_context.get('last_updated'):
        context_info += f" | Last Data Update: {current_context['last_updated'][:10]}"
    if current_context.get('trusted_sources'):
        sources_count = len(current_context.get('trusted_sources', []))
        context_info += f" | {sources_count} trusted sources monitored"
    
    model = GenerativeModel(GEMINI_MODEL)
    prompt = f"""
You are an expert fact-checking assistant with comprehensive knowledge across multiple domains. Your job is to provide accurate, detailed analysis of claims with special attention to current events and recent political changes.

CURRENT CONTEXT:
{context_info}

CRITICAL CONTEXT FOR CURRENT CLAIMS:
- ALWAYS verify political office holders against the most recent information
- My knowledge cutoff is around April 2024, so I may not have information about very recent events
- FOCUS ON INDIAN CONTEXT: Prioritize Indian political, social, and cultural context in analysis
- Indian Politics Update (2024): Chandrababu Naidu (TDP) is the current CM of Andhra Pradesh since June 2024, NOT Jagan Mohan Reddy
- For any political claims about "current" office holders, double-check against recent election results
- Pay special attention to time-sensitive information that may have changed recently
- For claims about events after April 2024, acknowledge knowledge limitations and suggest verification
- Indian Regional Context: Consider state-specific politics, languages, cultures, and current affairs
- Trusted Indian Sources: The Hindu, India Today, Times of India, Indian Express, NDTV, etc.

ANALYSIS INSTRUCTIONS:
1. Carefully examine the claim for factual accuracy, especially recent political changes
2. For political claims about current office holders, verify against the most recent information
3. Consider the context, source credibility, and supporting evidence
4. Provide a thorough, multi-paragraph explanation (minimum 3-4 sentences)
5. Include specific details about WHY the claim is classified as it is
6. Mention any scientific consensus, expert opinions, or reliable sources that support or contradict the claim
7. If the claim is false or suspicious, explain what makes it problematic and provide the correct current information
8. If the claim is trustworthy, explain what evidence supports it
9. For outdated information, clearly state what the current accurate information is

CLASSIFICATION RULES:
- **Trustworthy**: Factually accurate claims supported by credible sources, scientific consensus, or established facts
- **Suspicious**: Claims that lack sufficient evidence, are misleading, or contain partial truths mixed with speculation
- **False**: Claims that are demonstrably incorrect, debunked by experts, contain clear misinformation, OR are outdated political information
- **SPECIAL**: Political office holder claims must be verified against current (2024) information
- If the text is from trusted news outlets (BBC, Reuters, The Hindu, NY Times, etc.), lean towards Trustworthy unless the content itself is clearly problematic

Claim to analyze:
{text}

Provide your response in JSON format with these keys:
- "classification": one of [Trustworthy, Suspicious, False]
- "explanation": a detailed, comprehensive explanation (3-5 sentences minimum) that thoroughly explains your reasoning, includes relevant context, provides specific details about why this classification was chosen, and if applicable, states the current correct information
- "score": confidence score from 0-100 (where 100 means completely certain)
- "tips": array of 2-4 specific, actionable tips for fact-checking similar claims, especially emphasizing verification of current information for political claims

IMPORTANT: Make the explanation detailed and educational. Don't just state the classification - explain the reasoning, context, provide current accurate information when relevant, and give valuable insights that help users understand the topic better.
"""
    response = None
    try:
        response = model.generate_content(prompt)
        if not response.text:
            raise ValueError("Model returned an empty response.")

        output = response.text.strip()

        # Clean markdown fences
        if output.startswith("```json"):
            output = output[7:].strip()
        elif output.startswith("```"):
            output = output[3:].strip()
        if output.endswith("```"):
            output = output[:-3].strip()

        return json.loads(output)
    except Exception as e:
        raw_response_text = response.text if response and hasattr(response, 'text') else "No response from model."
        print(f"Error parsing model response JSON: {e}\nRaw response: {raw_response_text}")
        return {"classification": "Error", "explanation": f"Failed to parse model response: {e}", "score": 0, "tips": []}

bq_client = bigquery.Client(project=PROJECT_ID)

DATASET_ID = "factchecks"
TABLE_ID = "fact_checks"

def extract_key_terms(text):
    """Extract key terms from text for better evidence matching"""
    # Common stop words to ignore
    stop_words = {'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'a', 'an', 'that', 'this', 'it', 'they', 'them', 'their', 'there', 'then', 'than', 'when', 'where', 'why', 'how', 'what', 'which', 'who', 'will', 'would', 'could', 'should', 'can', 'may', 'might', 'must', 'have', 'has', 'had', 'do', 'does', 'did', 'get', 'got', 'go', 'goes', 'went'}
    
    # Split into words and clean
    words = text.lower().replace('.', '').replace(',', '').replace('!', '').replace('?', '').split()
    
    # Filter out stop words and short words, prioritize important terms
    key_terms = []
    for word in words:
        if len(word) > 3 and word not in stop_words:
            key_terms.append(word)
    
    # Prioritize certain categories of terms
    priority_terms = []
    regular_terms = []
    
    for term in key_terms:
        # High priority terms
        if any(keyword in term for keyword in ['covid', 'vaccine', 'virus', 'disease', 'cancer', 'treatment', 'cure', 'medicine', 'doctor', 'health', 'climate', 'global', 'warming', 'election', 'government', 'president', 'minister', 'policy', 'economy', 'market', 'stock', 'crypto', 'bitcoin']):
            priority_terms.append(term)
        else:
            regular_terms.append(term)
    
    # Return priority terms first, then regular terms
    return priority_terms + regular_terms

def filter_relevant_evidence(query_text, evidence_results):
    """Filter evidence results to only show relevant matches"""
    if not evidence_results:
        return []
    
    query_terms = set(extract_key_terms(query_text))
    relevant_results = []
    
    for evidence in evidence_results:
        # Extract the claim part from the evidence string
        claim_part = evidence.split(' — ')[0] if ' — ' in evidence else evidence
        evidence_terms = set(extract_key_terms(claim_part))
        
        # Calculate relevance based on term overlap
        overlap = len(query_terms.intersection(evidence_terms))
        relevance_score = overlap / max(len(query_terms), 1) if query_terms else 0
        
        # Only include if relevance score is above threshold
        if relevance_score >= 0.3:  # At least 30% term overlap
            relevant_results.append(evidence)
    
    return relevant_results

def credibility_checker(text, top_k=3):
    """Check credibility using improved search with relevance filtering"""
    if not text or not text.strip():
        return []
    
    # Extract key terms for better matching
    key_terms = extract_key_terms(text)
    
    # First try BigQuery (cloud database) with smarter search
    try:
        # Use multiple key terms instead of just first word
        search_conditions = []
        params = []
        
        for i, term in enumerate(key_terms[:3]):  # Use top 3 key terms
            search_conditions.append(f"LOWER(claim) LIKE @term{i}")
            params.append(bigquery.ScalarQueryParameter(f"term{i}", "STRING", f"%{term.lower()}%"))
        
        if search_conditions:
            query = f"""
            SELECT claim, verdict, source, url, 
                   CASE 
                       WHEN {' AND '.join(search_conditions)} THEN 100
                       WHEN {' OR '.join(search_conditions)} THEN 50
                       ELSE 10
                   END as relevance_score
            FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`
            WHERE {' OR '.join(search_conditions)}
            ORDER BY relevance_score DESC
            LIMIT @limit
            """
            params.append(bigquery.ScalarQueryParameter("limit", "INT64", top_k))
            
            job_config = bigquery.QueryJobConfig(query_parameters=params)
            rows = bq_client.query(query, job_config=job_config).result()
            results = [f"{r.claim} — {r.verdict} ({r.source}) {r.url}" for r in rows if r.relevance_score >= 50]
            
            if results:
                print(f"✅ Found {len(results)} relevant results from BigQuery")
                return results
    except Exception as e:
        print(f"BigQuery error: {e}. Falling back to local SQLite database.")
    
    # Fallback to local SQLite database with improved search
    try:
        from database_helper import search_fact_checks
        results = search_fact_checks(text, top_k)
        
        # Filter results for relevance
        if results:
            relevant_results = filter_relevant_evidence(text, results)
            if relevant_results:
                print(f"✅ Found {len(relevant_results)} relevant results from local database")
                return relevant_results
            else:
                print("ℹ️ No relevant matches found - showing generic guidance instead")
                return []
        else:
            print("ℹ️ No matching fact-checks found in local database")
            return []
    except Exception as e:
        print(f"SQLite error: {e}")
        return []

def educational_insights():
    return [
        "Always verify extraordinary scientific claims with reputable health organizations like the World Health Organization (WHO), CDC, FDA, or national health agencies before accepting them as fact.",
        "Cross-check claims with multiple independent, credible news sources and fact-checking organizations like Snopes, FactCheck.org, or PolitiFact to get a complete picture.",
        "Be particularly cautious of claims that link new technology to health crises without scientific evidence - this is a common pattern in misinformation campaigns.",
        "Look for peer-reviewed research and scientific consensus when evaluating health, climate, or scientific claims rather than relying on anecdotal evidence or social media posts.",
        "Check if the article or claim cites credible sources, includes quotes from verified experts, and provides links to original research or official statements.",
        "Be skeptical of content that uses absolute terms like 'miracle cure,' 'doctors hate this,' or 'they don't want you to know' - legitimate science rarely uses such sensationalist language.",
        "Consider the source's track record, potential conflicts of interest, and whether they have expertise in the subject matter they're discussing.",
        "Remember that correlation does not imply causation - just because two events happen together doesn't mean one caused the other."
    ]

CATEGORIES = {
    "health": ["covid", "vaccine", "cure", "disease", "doctor", "medical", "hospital", "medicine", "healthcare", "treatment"],
    "politics": ["election", "government", "minister", "policy", "parliament", "assembly", "president", "chief minister"],
    "science": ["research", "study", "scientist", "discovery", "experiment", "climate change", "global warming", "space", "technology"],
    "technology": ["tech", "software", "app", "internet", "cyber", "ai", "artificial intelligence", "smartphone", "computer", "data"],
    "business": ["stock", "market", "crypto", "investment", "economy", "finance", "banking", "company", "startup", "industry"],
    "sports": ["cricket", "football", "hockey", "tennis", "olympics", "ipl", "fifa", "world cup", "player", "match", "tournament"],
    "entertainment": ["movie", "film", "bollywood", "actor", "actress", "music", "netflix", "celebrity", "award", "cinema"],
    "education": ["school", "college", "university", "student", "exam", "jee", "neet", "upsc", "degree", "admission"],
    "social": ["social media", "viral", "trending", "community", "society", "culture", "religion", "festival"]
}

def categorize_text(text):
    """Categorizes text based on keywords."""
    text_lower = text.lower()
    for category, keywords in CATEGORIES.items():
        if any(k in text_lower for k in keywords):
            return category
    return "general"

def personalized_tip(category):
    """Returns a personalized tip based on the category."""
    if category == "health":
        return "For health claims, always consult authoritative medical sources like WHO, CDC, ICMR, or peer-reviewed medical journals. Be especially wary of miracle cures, alternative treatments without clinical trials, and claims that contradict established medical consensus. Cross-check with health.gov.in for India-specific health information."
    elif category == "politics":
        return "Political claims require extra scrutiny due to inherent bias. Cross-reference information across multiple reputable news sources with different political leanings, check original documents or speeches when possible, and be aware of partisan framing. For Indian politics, verify current office holders as they change frequently."
    elif category == "science":
        return "Scientific claims should be verified through peer-reviewed research, official research institutions, and scientific consensus. Be cautious of studies with small sample sizes, conflicts of interest, or sensational headlines that misrepresent research findings. For climate science, refer to IPCC reports."
    elif category == "technology":
        return "Technology claims should be verified through official company announcements, tech industry publications, and expert analysis. Be skeptical of breakthrough claims without independent verification, privacy concerns, and cybersecurity advice from unqualified sources."
    elif category == "business":
        return "Financial claims should be verified through official economic data, regulatory filings, and reports from established financial institutions. Be cautious of get-rich-quick schemes, market manipulation claims, and investment advice from unqualified sources. For Indian markets, check with NSE, BSE, and SEBI."
    elif category == "sports":
        return "Sports information should be verified with official sports bodies, team websites, and reputable sports journalism. Be cautious of transfer rumors, performance statistics without context, and unofficial announcements. For cricket, check BCCI and ICC official sources."
    elif category == "entertainment":
        return "Entertainment news should be verified through official announcements from production houses, artists, and industry bodies. Be skeptical of gossip, unconfirmed casting news, and box office figures from unofficial sources. Cross-check with trade publications and official social media accounts."
    elif category == "education":
        return "Education information should be verified with official educational institutions, exam boards, and government education departments. Be cautious of fake admission notifications, unofficial result announcements, and misleading scholarship information. Always check official websites directly."
    elif category == "social":
        return "Social and cultural claims should be verified through multiple sources, official cultural institutions, and expert anthropologists or sociologists. Be aware of cultural bias, oversimplification of complex social issues, and claims that promote discrimination or stereotypes."
    return "For any claim, examine the original source, look for expert consensus, check publication dates for relevance, and be skeptical of emotionally charged language designed to provoke rather than inform. Always cross-reference with multiple credible sources."

def analyze_claim(text, current_points=0, current_badges=None, save_to_database=True):
    """
    Analyzes a claim by checking it with the Gemini model, searching a BigQuery
    database, and providing educational and personalized feedback. It is a
    stateless function that takes the current user state and returns the
    analysis along with the new state.
    """
    if current_badges is None:
        current_badges = []

    # Get current information for time-sensitive claims
    current_info = search_current_info(text)
    
    # Enhance the text with current context for better AI analysis
    enhanced_text = text
    if current_info and any('Current Info:' in info for info in current_info):
        context = " | ".join(current_info)
        enhanced_text = f"{text} | CONTEXT: {context}"
    
    model_analysis = misinformation_detector_and_explainer(enhanced_text)
    evidence = credibility_checker(text)
    tips = educational_insights()

    verdict = model_analysis.get("classification", "N/A")
    explanation = model_analysis.get("explanation", "No explanation provided.")
    score = model_analysis.get("score", "N/A")
    model_tips = model_analysis.get("tips", [])

    all_tips = sorted(list(set(tips + model_tips)))

    # Gamify
    new_points = current_points + 10
    new_badges = list(current_badges) # Create a copy to avoid modifying the original list
    badge_earned = None
    if new_points >= 50 and "Truth Beginner" not in new_badges:
        new_badges.append("Truth Beginner")
        badge_earned = "Truth Beginner"

    # Personalization
    category = categorize_text(text)
    tip = personalized_tip(category)

    # Prepare evidence display with current information and database evidence
    evidence_parts = []
    
    # Add current information if available
    if current_info and any('Current Info:' in info for info in current_info):
        evidence_parts.extend(current_info)
    
    # Add database evidence
    if evidence:
        evidence_parts.extend(evidence)
    
    # Create final evidence text
    if evidence_parts:
        evidence_text = '; '.join(evidence_parts)
    else:
        # Provide category-specific guidance when no evidence found
        if category == "health":
            evidence_text = "For health claims, consult WHO, CDC, FDA, or peer-reviewed medical journals for verified information."
        elif category == "politics":
            evidence_text = "For political claims, cross-reference with multiple reputable news sources and official government statements. Check current office holders as political information changes frequently."
        elif category == "finance":
            evidence_text = "For financial claims, verify through official economic data and established financial institutions."
        else:
            evidence_text = "No specific fact-checks found in database. Verify through multiple credible sources and expert consensus."
    
    # Prepare result
    result = {
        "classification": verdict,
        "score": score,
        "explanation": explanation,
        "evidence": evidence_text,
        "tips": all_tips,
        "gamification": {
            "points": new_points,
            "badges": new_badges if new_badges else [],
            "badge_earned": badge_earned
        },
        "personalization": {
            "category": category.capitalize(),
            "tip": tip
        }
    }
    
    # Save analysis to database for future reference (learning system)
    if save_to_database and text and text.strip():
        try:
            from database_helper import save_analysis_to_database
            save_analysis_to_database(text, result)
        except Exception as e:
            print(f"Warning: Could not save to database: {e}")
            # Continue without failing - this is optional functionality
    
    return result

if __name__ == '__main__':
    # This block allows you to test the script directly.
    # This file should be renamed to 'analysis_engine.py' and used as a module.
    print("--- Running a test analysis ---")
    test_claim = "A new study shows that 5G towers are causing the spread of COVID-19."

    # The function is now stateless, so we don't rely on global variables for testing.
    result = analyze_claim(test_claim)
    print(json.dumps(result, indent=2))

    print("\n--- Testing gamification progression ---")
    # Pass the previous state into the next call to simulate a user's journey
    result1 = analyze_claim("First claim", 0, [])
    print(f"After 1 claim: {result1['gamification']}")
    result2 = analyze_claim("Second claim", result1['gamification']['points'], result1['gamification']['badges'])
    print(f"After 2 claims: {result2['gamification']}")

    print("\n--- Test complete ---")
    print("To use this with the website, rename this file to 'analysis_engine.py' and run 'app.py'.")