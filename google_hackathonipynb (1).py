# -*- coding: utf-8 -*-
"""Google Hackathonipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-8iqTScxmS3OzIenY8zPG7SJvbmjvwfL
"""

# 3rd attempt

!pip install --upgrade google-cloud-aiplatform google-cloud-bigquery gradio scikit-learn

from google.colab import auth
auth.authenticate_user()
print("‚úÖ Authenticated")

PROJECT_ID = "sodium-hope-470917-u6"   # <-- replace with your project ID
LOCATION = "us-central1"

from google.cloud import aiplatform
import vertexai
from vertexai.generative_models import GenerativeModel

aiplatform.init(project=PROJECT_ID, location=LOCATION)
vertexai.init(project=PROJECT_ID, location=LOCATION)

print("‚úÖ Vertex AI initialized for project:", PROJECT_ID)

from urllib.parse import urlparse

TRUSTED_DOMAINS = ["thehindu.com", "bbc.com", "nytimes.com", "indiatoday.in", "reuters.com"]

def precheck_url(url):
    domain = urlparse(url).netloc
    if any(d in domain for d in TRUSTED_DOMAINS):
        return "Trustworthy (Trusted News Source)"
    return None

import json

def misinformation_detector_and_explainer(text):
    if not text or text.strip() == "":
        return {"classification": "NoText", "explanation": "No explanation (empty input).", "score": 0, "tips": []}

    model = GenerativeModel("gemini-2.5-pro")
    prompt = f"""
You are a fact-checking assistant.

Rules:
- If the text is from a trusted news outlet (The Hindu, BBC, Reuters, etc.), treat it as **Trustworthy reporting**, even if it contains recent or future dates.
- Do not mark articles as False just because the events are dated in the near future.
- Only classify as False if the content itself contains proven misinformation or hoaxes.

Classify the text as one of: Trustworthy, Suspicious, False.

Text:
{text}

Respond ONLY in JSON format with the keys "classification", "explanation", "score" (0-100), and "tips" (a list of strings).
"""
    try:
        response = model.generate_content(prompt)
        output = response.text.strip()

        # Clean markdown fences
        if output.startswith("```json"):
            output = output[7:].strip()
        elif output.startswith("```"):
            output = output[3:].strip()
        if output.endswith("```"):
            output = output[:-3].strip()

        return json.loads(output)
    except Exception as e:
        print(f"Error parsing model response JSON: {e}\nRaw response: {response.text}")
        return {"classification": "Error", "explanation": f"Failed to parse model response: {e}", "score": 0, "tips": []}

from google.cloud import bigquery
bq_client = bigquery.Client(project=PROJECT_ID)

DATASET_ID = "factchecks"
TABLE_ID = "fact_checks"

def credibility_checker(text, top_k=3):
    token = text.split()[0].lower().replace("'", "").replace('"', '')
    query = f"""
    SELECT claim, verdict, source, url
    FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`
    WHERE LOWER(claim) LIKE '%{token}%'
    LIMIT {top_k}
    """
    try:
        rows = bq_client.query(query).result()
        return [f"{r.claim} ‚Äî {r.verdict} ({r.source}) {r.url}" for r in rows]
    except Exception as e:
        print(f"BigQuery error: {e}")
        return []

def educational_insights():
    return [
        "Check if the article cites WHO, CDC, or government sources.",
        "Cross-check claims with multiple independent outlets.",
        "Avoid trusting content with absolute terms like 'miracle cure'."
    ] # Added closing parenthesis

user_points = 0
user_badges = []

def gamify_progress():
    global user_points, user_badges
    badge_earned = None

    if user_points >= 50 and "Truth Beginner" not in user_badges:
        user_badges.append("Truth Beginner")
        badge_earned = "üèÖ Truth Beginner"

    progress = f"Points: {user_points}\nBadges: {', '.join(user_badges) if user_badges else 'None'}"
    if badge_earned:
        progress += f"\nüéâ New Badge Earned: {badge_earned}!"
    return progress

CATEGORIES = {
    "health": ["covid", "vaccine", "cure", "disease", "doctor"],
    "politics": ["election", "government", "minister", "policy"],
    "finance": ["stock", "market", "crypto", "investment"]
}

def categorize_text(text):
    text_lower = text.lower()
    for category, keywords in CATEGORIES.items():
        if any(k in text_lower for k in keywords):
            return category
    return "general"

def personalized_tip(category):
    if category == "health":
        return "Always verify medical claims with WHO or CDC."
    elif category == "politics":
        return "Check political claims across multiple outlets to avoid bias."
    elif category == "finance":
        return "Be careful with financial claims ‚Äî cross-check with trusted economic reports."
    return "Look for sources and avoid emotional headlines."

def analyze_claim(text):
    global user_points
    model_analysis = misinformation_detector_and_explainer(text)
    evidence = credibility_checker(text)
    tips = educational_insights()

    verdict = model_analysis.get("classification", "N/A")
    explanation = model_analysis.get("explanation", "No explanation provided.")
    score = model_analysis.get("score", "N/A")
    model_tips = model_analysis.get("tips", [])

    all_tips = list(set(tips + model_tips))

    # Gamify
    user_points += 10
    gamification = gamify_progress()

    # Personalization
    category = categorize_text(text)
    personalized = personalized_tip(category)

    return f"""
üü¢ Gemini Verdict & Explanation:
Classification: {verdict}
Score: {score}
Explanation: {explanation}

üìå Evidence from DB:
{'; '.join(evidence) if evidence else "No direct evidence found."}

üìù Educational Tips:
- {"\n- ".join(all_tips) if all_tips else "No tips available."}

üéÆ Gamified Progress:
{gamification}

üìä Personalized Learning:
Category: {category.capitalize()}
Tip: {personalized}
"""

import gradio as gr

def gradio_text_fn(txt):
    return analyze_claim(txt)

with gr.Blocks(title="Thunderwing Falcons - AI Fact Checker") as demo:
    gr.Markdown(
        """
        # ü¶Ö Thunderwing Falcons
        ## AI Fact-Checker (Text Only)
        ---
        Enter any claim below and our system will analyze it using **Gemini + Fact-Check + Gamified Learning**.
        """
    )

    with gr.Row():
        with gr.Column():
            input_box = gr.Textbox(
                lines=2,
                placeholder="Enter a claim to fact-check...",
                label="Claim"
            )
            submit_btn = gr.Button("üöÄ Submit")

        with gr.Column():
            output_box = gr.Textbox(
                lines=20,
                label="AI Fact-Checker Output"
            )

    submit_btn.click(fn=gradio_text_fn, inputs=input_box, outputs=output_box)

    # Footer
    gr.Markdown(
        """
        ---
        ‚ö° **Created by Team Thunderwing Falcons**
        Electrifying speed meets sharp precision
        """
    )

demo.launch(share=True)